# å¼ºåŒ–å­¦ä¹ ç‚’è‚¡ï¼Œèµ°å‘äººç”Ÿå·…å³°ï¼ˆæˆ–å€¾å®¶è¡äº§ï¼‰

## å…è´£å£°æ˜
- æœ¬ç½‘ç«™æ‰€è½½çš„èµ„æ–™å¹¶ä¸æ„æˆæŠ•èµ„çš„æ„è§æˆ–å»ºè®®ï¼Œæ®æ­¤æ“ä½œé£é™©è‡ªæ‹…ã€‚è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ï¼


## Quickstart
#### 1. æ•°æ®è·å–
```
nohup python -u python data/get_stock_data_train.py > get_train.log 2>&1 &
nohup python -u python data/get_stock_data_test.py > get_test.log 2>&1 &
```
#### 2. è®¾ç½®é…ç½®æ–‡ä»¶config.yaml(ä¹Ÿå¯ä½¿ç”¨é»˜è®¤é…ç½®å‚æ•°)
#### 3. è¿è¡Œæ¨¡å‹
```
python main.py
```


## ä»£ç å‚è€ƒ
æœ¬é¡¹ç›®çš„ä»£ç å‚è€ƒäº†ä»¥ä¸‹ä¸¤ä¸ªrepo,æ„Ÿè°¢åŸä½œè€…ï¼å‚è€ƒå†…å®¹åŒ…æ‹¬è‚¡ç¥¨Gymç¯å¢ƒã€è‚¡ç¥¨æ•°æ®è·å–ã€ç»“æœçš„å¯è§†åŒ–ã€‚
- [RL-Stock](https://github.com/wangshub/RL-Stock)
- [Create custom gym environments from scratch â€” A stock market example](https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e)

ä¸»è¦æ”¹åŠ¨:
1. è°ƒæ•´ä»£ç ç»“æ„,å¢åŠ é…ç½®æ–‡ä»¶
2. RLç®—æ³•æ¨¡å‹ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„stable-baselines3ï¼Œä¹‹å‰çš„stable-baselineså·²å¤„äºç»´æŠ¤çŠ¶æ€ï¼Œä¸”å®¹æ˜“é‡åˆ°tensorflowç‰ˆæœ¬ä¸å…¼å®¹çš„é—®é¢˜
3. ä¸°å¯ŒRLæ¨¡å‹
4. å¢åŠ äº¤æ˜“æ‰‹ç»­è´¹
5. è‚¡ç¥¨ä»·æ ¼åå¤æƒ

todo:
- å°†ç‰¹å¾æ¥å£æŠ½å‡ºæ¥
- å°†æ¨¡å‹æ¥å£æŠ½å‡ºæ¥
- å°†rewardçš„å®šä¹‰æŠ½å‡ºæ¥
- ç‰¹å¾ä¼˜åŒ–
- æ¨¡å‹ä¼˜åŒ–

## è‚¡ç¥¨æ•°æ®
- æ•°æ®å’Œæ–¹æ³•çš†æ¥æºäºç½‘ç»œï¼Œæœ¬é¡¹ç›®å¼€å‘è€…æ— æ³•ä¿è¯æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ï¼

- è‚¡ç¥¨è¯åˆ¸æ•°æ®é›†æ¥è‡ªäº [baostock](http://baostock.com/baostock/index.php/Python_API%E6%96%87%E6%A1%A3)ï¼Œä¸€ä¸ªå…è´¹ã€å¼€æºçš„è¯åˆ¸æ•°æ®å¹³å°ï¼Œæä¾› Python APIã€‚

- é¡¹ç›®ä¸­å°†1990-01-01è‡³2019-11-29çš„è‚¡ç¥¨æ•°æ®ä½œä¸ºè®­ç»ƒé›†ï¼Œä¹‹åçš„ä¸€ä¸ªæœˆ(2019-12-01è‡³2019-12-31)æ•°æ®ä½œä¸ºæµ‹è¯•é›†


## ğŸ¤– OpenAI Gym è‚¡ç¥¨äº¤æ˜“ç¯å¢ƒ

### è§‚æµ‹ Observation

ç­–ç•¥ç½‘ç»œè§‚æµ‹çš„å°±æ˜¯ä¸€åªè‚¡ç¥¨çš„å„é¡¹å‚æ•°ï¼Œæ¯”å¦‚å¼€ç›˜ä»·ã€æ”¶ç›˜ä»·ã€æˆäº¤æ•°é‡ç­‰ã€‚éƒ¨åˆ†æ•°å€¼ä¼šæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„æ•°å€¼ï¼Œæ¯”å¦‚æˆäº¤é‡‘é¢æˆ–è€…æˆäº¤é‡ï¼Œæœ‰å¯èƒ½ç™¾ä¸‡ã€åƒä¸‡ä¹ƒè‡³æ›´å¤§ï¼Œä¸ºäº†è®­ç»ƒæ—¶ç½‘ç»œæ”¶æ•›ï¼Œè§‚æµ‹çš„çŠ¶æ€æ•°æ®è¾“å…¥æ—¶ï¼Œå¿…é¡»è¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œå˜æ¢åˆ° `[-1, 1]` çš„åŒºé—´å†…ã€‚

|å‚æ•°åç§°|å‚æ•°æè¿°|è¯´æ˜|
|---|---|---|
|date|äº¤æ˜“æ‰€è¡Œæƒ…æ—¥æœŸ|æ ¼å¼ï¼šYYYY-MM-DD|
|code|è¯åˆ¸ä»£ç |æ ¼å¼ï¼šsh.600000ã€‚shï¼šä¸Šæµ·ï¼Œszï¼šæ·±åœ³|
|open|ä»Šå¼€ç›˜ä»·æ ¼|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|high|æœ€é«˜ä»·|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|low|æœ€ä½ä»·|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|close|ä»Šæ”¶ç›˜ä»·|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|preclose|æ˜¨æ—¥æ”¶ç›˜ä»·|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|volume|æˆäº¤æ•°é‡|å•ä½ï¼šè‚¡|
|amount|æˆäº¤é‡‘é¢|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|adjustflag|å¤æƒçŠ¶æ€|ä¸å¤æƒã€å‰å¤æƒã€åå¤æƒ|
|turn|æ¢æ‰‹ç‡|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½ï¼›å•ä½ï¼š%|
|tradestatus|äº¤æ˜“çŠ¶æ€|1ï¼šæ­£å¸¸äº¤æ˜“ 0ï¼šåœç‰Œ|
|pctChg|æ¶¨è·Œå¹…ï¼ˆç™¾åˆ†æ¯”ï¼‰|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½|
|peTTM|æ»šåŠ¨å¸‚ç›ˆç‡|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½|
|psTTM|æ»šåŠ¨å¸‚é”€ç‡|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½|
|pcfNcfTTM|æ»šåŠ¨å¸‚ç°ç‡|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½|
|pbMRQ|å¸‚å‡€ç‡|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½|

### åŠ¨ä½œ Action

å‡è®¾äº¤æ˜“å…±æœ‰**ä¹°å…¥**ã€**å–å‡º**å’Œ**ä¿æŒ** 3 ç§æ“ä½œï¼Œå®šä¹‰åŠ¨ä½œ(`action`)ä¸ºé•¿åº¦ä¸º 2 çš„æ•°ç»„

- `action[0]` ä¸ºæ“ä½œç±»å‹ï¼›
- `action[1]` è¡¨ç¤ºä¹°å…¥æˆ–å–å‡ºç™¾åˆ†æ¯”ï¼›

| åŠ¨ä½œç±»å‹ `action[0]` | è¯´æ˜ |
|---|---|
| 1 | ä¹°å…¥ `action[1]`|
| 2 | å–å‡º `action[1]`|
| 3 | ä¿æŒ |

æ³¨æ„ï¼Œå½“åŠ¨ä½œç±»å‹ `action[0] = 3` æ—¶ï¼Œè¡¨ç¤ºä¸ä¹°ä¹Ÿä¸æŠ›å”®è‚¡ç¥¨ï¼Œæ­¤æ—¶ `action[1]` çš„å€¼æ— å®é™…æ„ä¹‰ï¼Œç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒAgent ä¼šæ…¢æ…¢å­¦ä¹ åˆ°è¿™ä¸€ä¿¡æ¯ã€‚

### å¥–åŠ± Reward

å¥–åŠ±å‡½æ•°çš„è®¾è®¡ï¼Œå¯¹å¼ºåŒ–å­¦ä¹ çš„ç›®æ ‡è‡³å…³é‡è¦ã€‚
æä¾›ä¸¤ä¸ªrewardçš„è®¾è®¡æ–¹æ¡ˆ: 

```
# reward 1:
# åˆ©æ¶¦ä¸ºæ­£æ—¶rewardä¸º1; å½“åˆ©æ¶¦ä¸ºè´Ÿå€¼æ—¶ï¼Œrewardä¸º-100
reward = self.net_worth - INITIAL_ACCOUNT_BALANCE
reward = 1 if reward > 0 else -100
```

```
# reward 2:
# è´¦æˆ·ä½™é¢ä¹˜ä»¥æ—¶é—´ç³»æ•°(é¿å…æ—©æœŸé˜¶æ®µè¿‡å¿«åœ°å¥–åŠ±Agent,ä½¿å¾—å®ƒè¿›è¡Œå……åˆ†æ¢ç´¢ï¼›å¯¹äºé•¿æœŸä¿æŒé«˜ç°é‡‘æµè¿›è¡Œå¥–åŠ±)
# delay_modifier = (self.current_step / MAX_STEPS)
# reward = self.balance * delay_modifier
```

## RLç®—æ³•
- PPO
- A2C

## ğŸ•µï¸â€â™€ï¸ å•åªè‚¡ç¥¨æ¨¡æ‹Ÿå®éªŒç»“æœ

- åˆå§‹æœ¬é‡‘ `10000`
- è‚¡ç¥¨ä»£ç ï¼š`sh.600000`
- è®­ç»ƒé›†ï¼š `stockdata/train/sh.600000.æµ¦å‘é“¶è¡Œ.csv`
- æµ‹è¯•é›†ï¼š `stockdata/test/sh.600000.æµ¦å‘é“¶è¡Œ.csv`
- æ¨¡æ‹Ÿæ“ä½œ `20` å¤©

ç›ˆåˆ©æƒ…å†µ:

PPO: ç›ˆåˆ©`415`
<img src="img/sh.600000_PPO.png" alt="drawing" width="70%"/>

A2C: äºæŸ`534`
<img src="img/sh.600000_A2C.png" alt="drawing" width="70%"/>




## ğŸ“š å‚è€ƒèµ„æ–™
1. [Create custom gym environments from scratch â€” A stock market example](https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e)
2. [RL-Stock](https://github.com/wangshub/RL-Stock)
3. Deep-Reinforcement-Learning-Hands-On, chapter 10
