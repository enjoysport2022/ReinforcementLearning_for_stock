# å¼ºåŒ–å­¦ä¹ ç‚’è‚¡ï¼Œèµ°å‘äººç”Ÿå·…å³°ï¼ˆæˆ–å€¾å®¶è¡äº§ï¼‰

## å…è´£å£°æ˜
- æœ¬ç½‘ç«™æ‰€è½½çš„èµ„æ–™å¹¶ä¸æ„æˆæŠ•èµ„çš„æ„è§æˆ–å»ºè®®ï¼Œæ®æ­¤æ“ä½œé£é™©è‡ªæ‹…ã€‚è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ï¼


## Quickstart
#### 1. æ•°æ®è·å–
```
cd data
nohup python -u get_stock_data_train.py > get_train.log 2>&1 &
nohup python -u get_stock_data_test.py > get_test.log 2>&1 &
```
#### 2. è®¾ç½®é…ç½®æ–‡ä»¶config.yaml(ä¹Ÿå¯ä½¿ç”¨é»˜è®¤é…ç½®å‚æ•°)
#### 3. è¿è¡Œæ¨¡å‹
```
python main.py
```


## ä»£ç å‚è€ƒ
æœ¬é¡¹ç›®çš„ä»£ç å‚è€ƒäº†ä»¥ä¸‹ä¸¤ä¸ªrepo,æ„Ÿè°¢åŸä½œè€…ï¼å‚è€ƒå†…å®¹åŒ…æ‹¬è‚¡ç¥¨Gymç¯å¢ƒã€è‚¡ç¥¨æ•°æ®è·å–ã€ç»“æœçš„å¯è§†åŒ–ã€‚
- [RL-Stock](https://github.com/wangshub/RL-Stock)
- [Create custom gym environments from scratch â€” A stock market example](https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e)

ä¸»è¦æ”¹åŠ¨:
1. è°ƒæ•´ä»£ç ç»“æ„,å¢åŠ é…ç½®æ–‡ä»¶
2. RLç®—æ³•æ¨¡å‹ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„stable-baselines3ï¼Œä¹‹å‰çš„stable-baselineså·²å¤„äºç»´æŠ¤çŠ¶æ€ï¼Œä¸”å®¹æ˜“é‡åˆ°tensorflowç‰ˆæœ¬ä¸å…¼å®¹çš„é—®é¢˜
3. ä¸°å¯ŒRLæ¨¡å‹
4. å¢åŠ äº¤æ˜“æ‰‹ç»­è´¹
5. è‚¡ç¥¨ä»·æ ¼åå¤æƒ
6. ç‰¹å¾ä¼˜åŒ–
7. æµ‹è¯•é›†é•¿åº¦è®¾ç½®ä¸º1å¹´

todo:
- å°†ç‰¹å¾æ¥å£æŠ½å‡ºæ¥
- å°†æ¨¡å‹æ¥å£æŠ½å‡ºæ¥
- å°†rewardçš„å®šä¹‰æŠ½å‡ºæ¥
- ç‰¹å¾ä¼˜åŒ–: å†å²ç»Ÿè®¡ä¿¡æ¯
- ç‰¹å¾ä¼˜åŒ–: æ¨¡å‹é¢„æµ‹ç»“æœ
- ç‰¹å¾ä¼˜åŒ–: å¤–éƒ¨æ•°æ®,å¦‚å¤©æ°”
- ç­–ç•¥ä¼˜åŒ–: ç»„åˆç­–ç•¥
- é€‰è‚¡è¯´æ˜
- æ¨¡å‹ä¼˜åŒ–
- å¯è§†åŒ–ä¼˜åŒ–

## RLç®—æ³•
- PPO
- A2C

## ğŸ•µï¸â€â™€ï¸ å•åªè‚¡ç¥¨æ¨¡æ‹Ÿå®éªŒç»“æœ

- åˆå§‹æœ¬é‡‘ `100000`
- è‚¡ç¥¨ä»£ç ï¼š`sh.600006`
- è®­ç»ƒé›†ï¼š1990-01-01è‡³2019-12-31
- æµ‹è¯•é›†ï¼š2020-01-01è‡³2020-12-31
- æ¨¡æ‹Ÿæ“ä½œ `242` å¤©

ç›ˆåˆ©æƒ…å†µ:

PPO: ç›ˆåˆ©`77801`

<img src="img/sh.600006_PPO.png" alt="drawing" width="100%"/>


A2C: ç›ˆåˆ©`23054`

<img src="img/sh.600006_A2C.png" alt="drawing" width="100%"/>


## ğŸ“š å‚è€ƒèµ„æ–™
1. [Create custom gym environments from scratch â€” A stock market example](https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e)
2. [RL-Stock](https://github.com/wangshub/RL-Stock)
3. Deep-Reinforcement-Learning-Hands-On, chapter 10
